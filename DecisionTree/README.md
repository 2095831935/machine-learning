<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# 一、相关介绍
## 1.1 决策树的相关术语
信息：如果待分类的事务可能划分在多个分类之中，则事务$ x_i $的信息定义为：$ l(x_i)=-log_2p(x_i) $  
熵：信息的期望值，通过公式$ H=-\sum_{i=1}^n p(x_i) log_2p(x_i) $，其中$ n $是分类的数目；  
信息增益：根据某个特征划分数据集获得的熵增加；  


## 1.2 决策树创建分支的伪代码createBranch()如下所示：
```
检测数据集中的每个子项是否属于同一分类  
    If so return 类标签；  
    Else  
        寻找划分数据集的最好特征  
        划分数据集  
        创建分支节点  
            for 每个划分的子集  
                调用函数createBranch并增加返回结果到分支节点中  
        return 分支节点 
 ```
 
## 1.3 构建决策树的一般流程
1. 收集数据：可以使用任何方法。
2. 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。
3. 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。
4. 训练算法：构造树的数据结构。
5. 测试算法：使用经验树计算错误率。
6. 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。

# 二、 算法分析
## 2.1 ID3算法分析
&emsp;&emsp;文件ID3_DecisionTree.md中实现的ID3算法没有考虑过度拟合的问题（overfitting），其次ID3无法直接处理数值型数据；
